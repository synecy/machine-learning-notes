{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "\n",
    "$ Loss(x,y,w) $\n",
    "\n",
    "Returns a scalar value representing our \"happiness\" to our prediction of $y$ with given $x$ and weight $w$\n",
    "\n",
    "Value closer to 0 the better. High loss bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score\n",
    "Weighted combination of features.\n",
    "\n",
    "Is our prediction.\n",
    "\n",
    "Also indicates **confidence** to our prediction.\n",
    "\n",
    "$w \\cdot \\phi(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Margin\n",
    "\n",
    "How correct we are. $y$ = +1 or -1 in binary classification.\n",
    "\n",
    "Indicates our **correctness**\n",
    "\n",
    "Distance from the data point to a decision boundary.\n",
    "\n",
    "The sign of score and margin should be the same if our prediction is correct.\n",
    "\n",
    "$(w \\cdot \\phi(x))y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-one loss\n",
    "Commonly used loss function with classification. *There are many others, this is just an example.*\n",
    "\n",
    "Did you make a mistake or not. Returns 1 if you made a mistake, 0 if not.\n",
    "\n",
    "$f^{}_w(x) = sign(w\\times\\phi(x))$\n",
    "\n",
    "$Loss^{}_{0-1}(x,y,w) = 1[f^{}_w(x)\\neq y] = 1[(\\underbrace{w \\cdot \\phi(x))y}_\\text{margin}\\leq 0]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual\n",
    "\n",
    "The amount which our prediction (score $f^{}_w(x)$) overshoots $y$\n",
    "\n",
    "$(w \\cdot \\phi(x))-y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squared loss\n",
    "\n",
    "$Loss^{}_{squared}(x,y,w) = (\\underbrace{f^{}_w(x)-y}_\\text{residual})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
